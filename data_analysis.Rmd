---
title: "R Notebook"
output: 
  github_document:
    toc: true
    toc_depth: 2
---
# Dada2
## chargement des librairies
```{r}
library(dada2)
library(phyloseq)
library(ggplot2)
library(dplyr)
library(reshape2)
library(ade4)
library(ggrepel)
library(lattice)
library(caret)
library(igraph)
library(ggnetwork)
theme_set(theme_bw())
```
## acquisition des données
```{bash}
wget https://pagesperso.univ-brest.fr/~maignien/teaching/M1-MFA/UE-Ecogenomique2/EcoG2_data_cc2.tar.gz
tar xvzf EcoG2_data_cc2.tar.gz
```

Ici nous récupérons la taxonomie silva afin d'analyser et d'assigner les taxonomies.
```{bash}
wget https://zenodo.org/record/3986799/files/silva_nr99_v138_train_set.fa.gz
```
## création d'une variable contenant les données
Nous avons donc les séquençages des régions v4-v5 des échantillons prélevés dans la rade de Brest le 10 septembre 2014 et le 11 mars 2015 à différentes profondeurs
```{r}
path <- "~/ECOG2_CC2/sequences_reunies" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
## filtration et éliminations des sequences basse qualité
```{r}
# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "R"), `[`,1)
# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)
print(fnRs)
```

```{r}
fnRs[1:11]
```
Le plot quality profile nous permets d'analyser les nucléotides pour lesquels la qualité du séquençage décroit. 
Pour les séquences forward, qui sont de meilleures qulités que les reverses dû à la méthode de séquençage, la qualité décroit à partir de 240 nucléotides. 
```{r}
plotQualityProfile(fnFs[1:3])
```
Pour les séquences reverse, la qualité décroit à partir de 150 nucléotides et le Q score devient vraiment mauvais à partir de 200 nucléotides.
```{r}
plotQualityProfile(fnRs[1:2])
```

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
sample.names
print(filtFs)
```
Nous coupons ici les séquences au niveau des nucléotides précédemment énoncés. Nous choisissons de ne couper qu'à 200 nucléotides pour les reverse pour garder un overlap assez important. 
```{r}
out<-filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,200),trimLeft=c(21),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
```

```{r}
head(out)
```
# Learn the Error Rates
 Nous allons ici utiliser des lignes de commandes qui vont permettre d'apprendre à la machine les différents profils d'erreurs générées lors du séquençage. L'opération est faite sur les séquences reverse et forward.
 
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
ici nous visualisons la probabilité d'obtenir une erreur de la machine remplaçant une base par une autre (A→C, A→G, ...) le taux d'erreur sont indiqués pour chaque combinaison possible pour les séquences reverse et forward. 
Chaque point représentent les taux d'erreur observés pour chaque score de qualité du consensus. La ligne noire montre le taux d'erreur estimés après convergence de l'algorithme d'apprentissage machine et la ligne rouge montre le taux d'erreur attendus selon la définition nominale du Q-score.
```{r}
plotErrors(errF, nominalQ=TRUE)
```

```{r}
plotErrors(errR, nominalQ=TRUE)
```
# Sample Inference
Ici nous créons une autre variable "dadaFs" dans laquelle nous mettons les fichiers obtenus après avoir filtré et appliqué le profil d'erreur à nos séquences. Nous allons faire la même chose avec dadaRS.

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
Cette commande nous permet de visualiser le résultat global qu'on retrouve classé dans la liste dadaFs. Ils nous indiquent que sur les séquences on retrouve 1010 séquences qui correspondent aux vrais variants, par rapport aux 37907 séquences. 
```{r}
dadaFs[[1]]
```
# Merge paired reads
Ici nous voulons mettre en une seule séquence double brin les Forwards et les Reverses. Nous pouvons faire cette opération grâce aux overlaps. Cela se fait grâce à un alignement entre les forwards et les reverses qui vont permettre de contruire les contigs.
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
# Construct sequence table
Nous allons construire une table des variations de séquence dans les amplicons (ASV) qui permet une meilleure résolution que les tables OTUs 97%
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
# Remove chimeras
Malgré qu'on ait pu appliquer les modèles d'erreurs aux séquences, il reste des chimères. Ces chimères sont facilement reconnaissables par la machine et peuvent etre réparées en y rajoutant les parties droites et gauche des 2 séquences les plus abondantes.
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
Ici on peut voir qu'on à 22% de chimères dans notre jeu de donnée. Ce chiffre important peut être dû à la qualité des séquences reverse qui était assez moyenne sur la fin.
```{r}
1-sum(seqtab.nochim)/sum(seqtab)
```
# Track reads through the pipeline
Ce code nous permet de visualiser le nombre de séquences obtenues à la suite de toutes nos manipulations de filtrage. Ici nous pouvons voir qu'on a pu récupérer la plupart de nos séquences brutes, ce qui est signe d'une bonne qualité de séquençage globale (malgré les 22% de chimères).
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
# Assign taxonomy

Nous créons ainsi une variable qui va recevoir les espèces obtenues grâce à Silva

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "/home/rstudio/ECOG2_CC2/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)
```

```{r}
taxa <- addSpecies(taxa, "/home/rstudio/ECOG2_CC2/silva_species_assignment_v138.fa.gz")
```
On remarque donc après avoir affiché la table qu'on a créée on obtient une majorité de  Alphaproteobacteries et plus précisément les bactéries de la clade SAR11 (=Candidatus Pelagibacter ubique). En effet, cet ordre de bactérie est l'ordre le plus représenté dans les océans : elle a une répartition mondiale. Ce résultat est donc cohérent. 
```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

# Taxonomic Filtering
création des variables permettant d'organiser les 11 échantillons selon la date et la profondeur.
```{r}
samples.out <- rownames(seqtab.nochim)
profondeur <- sapply(strsplit(samples.out, "_"), `[`, 2)
profondeur <- (sapply(strsplit(samples.out, "_"), `[`, 3))
date <- substr(profondeur,1,11)
samdf <- data.frame(Profondeur=profondeur, Date=date)
samdf$Profondeur <- c("Fond","Fond","Fond","Fond","Fond", "Median","Median","Surface","Surface","Surface","Surface")
samdf$Date[samdf$Profondeur==11] <- c("mars","sept")
rownames(samdf) <- samples.out
```
Entre temps nous avons dû créer une table manuellement afin de réorganiser les séquences, les informations de profondeurs et des dates ne correspondant pas.

# création de l'arbre phyloseq 
```{r}
library(phangorn)
library(DECIPHER)
seqs <- getSequences(seqtab.nochim)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```
```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa), phy_tree(fitGTR$tree))
ps
```
## Visualisation de l'alpha diversité 
L'alpha diversité permet de mesurer la richesse observée. L'alpha diversité peut se calculer de plusieurs façon grâce à différents indices, ce qui nous permet de les comparer. Ici nous pouvons voir que les communautés en mars, que ce soit pour les echantillons du fond et de surface, possède un indice d'alpha diversité similaire : ils contiennent une communauté de richesse semblables. Un indice avec une forte valeur traduit la présence d'une communauté qui prend le dessus sur les autres : nous savons donc qu'en mars, en surface et en profondeur, il y a des communautés dominantes qui seront retrouvées en grand nombre, et des communautés bien moins représentées.
En revanche, pour les échantillons prélevés en septembre, nous pouvons clairement distinguer des richesses différentes entre les profondeurs différentes auxquelles les échantillons ont été prélevés. Nous pouvons ainsi voir que les echantillons prélevés profondémment ont un indice d'alpha diversité élevé (et correspondant plus ou moins à celui retrouvé en Mars). Cela traduit deux choses : en profondeur, nous pouvons retrouver une structure communautaire stable car elle ne semble pas varier en fonction des saisons (concernant la structure, ici nous ne pouvons pas dire si ce sont les mêmes communautés qui dominent ou si elles changent en fonction des saisons). Cependant il faudrait faire un prélevement au printemps et en automne afin de s'assurer que cette hypothèse soit vraie. L'autre hypothèse que nous pouvons tirer de cela est qu'en profondeur, il y a surement moins de variation de température et de luminosité par rapport à la surface et à la profondeur médiane. Cela expliquerait la stabilité des structures communautaires en profondeur dû à la stabilité du milieu.
Le milieu médian n'a été étudié qu'en septembre. Cela ne nous permet pas d'en avoir un aperçu au cours du temps. Néanmoins, ce milieu a un indice alpha inférieur à celui du milieu profond, on peut voir que la communauté à une structure un peu plus partagée entre les espèces par rapport à celle de la profondeur.
A la surface, nous pouvons voir un indice bien plus faible par rapport aux autres milieu en septembre : les communautés présentent sont plus équitablement réparties, il y a moins de communautés minoritaires par rapport aux communautés majoritaires. Ces dernières sont présentes mais dans une moins dre mesure par rapport aux communautés profondes par exemple. 
En revanche, en mars, la structure des communautés change et devient semblable à celle des profondeurs, avec des OTUs qui vont devenir plus largement majoritaires et d'autres qui seront plus minoritaires.
```{r}
plot_richness(ps, x="Date", measures=c("Shannon", "Simpson"), color="Profondeur")
```
 Ces lignes de codes nous permettent de compter le nombre d'echantillons qu'on a pour chaque phylums.
```{r}
# Show available ranks in the dataset
rank_names(taxa.print)
```
Sur la table affichée, nous pouvons compter 12 échantillons qui n'ont pas de phyla defini. Cela peut etre dû à une mauvaise filtration : ce serait des artefacts.
On peut voir que les bactéries dominantes sont les Proteobactéria, les Bacteroidota et des Cyanobactéria. Ces 3 grands phylums contiennent bien des bactéries marines, ce qui est attendu. Nous pouvons voir plusieurs phylums comportant moins de 10 représentants, ils sont retirés. Cela peut être dû à des erreurs de taxonomie. Même si ce n'est pas le cas, au vu du peu de représentants présents pour ces phylums, nous pouvons les retirer car ils ne sont probablement pas très représentatifs de la structure de ces communautés. 
```{r}
# Create table, number of features for each phyla
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```
 Ce code nous permet de nous assurer ques les séquences pour lesquelles les anotations sont ambigues vont bien être retirées.

## Filtrage de la taxonomie

```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```
Ici nous allons mesurer la prévalence, qui sera dans le cadre de cette étude le nombre d'echantillons par taxon

```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```
Cette commande nous permet d'evaluer la prévalence moyenne de chaque phylum (colonne1) et la prévalence totale (colonne2). Cela nous permet de confirmer les résultats du dessus et de pouvoir éliminer les phylums peu importants.
```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```
Le code permettant de retirer ces taxons est ci-dessous.
```{r}
# Define phyla to filter
filterPhyla = c("Campilobacterota", "Dependentiae", " Crenarchaeota","Desulfobacterota", "Dadabacteria ", "Fibrobacterota", " Hydrogenedentes", "NB1-j", " PAUC34f", " Elusimicrobiota", "Gemmatimonadota", "Myxococcota")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```
# Prevalence Filtering
 Ces manipulations nous permettent de voir si nous avons manqué de voir des echantillons mal definis ou en tres faible quantité qui devraient etre retirés. On va aussi pouvoir avoir un aperçu des séquences qui sont rangées dans chaque features. 
Ici; chaque point représente un taxa. Nous ne voyons pas de seuil de prévalence clairement établi ici. Nous avons donc des taxons assez stables. Néanmoins nous pouvons fixer manuelle le seuil de prévalence quelque part entre 0 et 10% (en verifiant qu'il n'y a pas d'impact non attendu sur la suite de l'étude)

Sans surprise, les phylums les plus représentés sont ceux qui ont le plus de prévalence. 
```{r}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```
on va donc fixer un seuil de prévalence de 5%, c'est-à- dire que nous allons retirer toutes les valeurs de prévalence inferieures à 95%.
```{r}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```
C'est grâce à la fonction prune_taxa qu'on va pouvoir retirer les ASVs qui ne respectent pas le seuil de prévalence
```{r}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```

# Agglomerate taxa
on sait que les communautés microbiennes sont souvent composées de taxons qui partagent des caractéristiques communes. On va donc chercher à mettre ensemble les taxons qui sont très proches les uns de autres.
Pour cela, l'aggregation taxonomique est pratique. Elle est facile, et on peut comparer les taxons grâce à des arbres simples à rangs. Pour le generer on va pouvoir utiliser phyloseq. La première chose qui sera faite sera d'agglomerer ensemble les échantillons du même genre. 
```{r}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```
tax_glom est une fonction qui permet de rassembler les espèces ayant une taxonomie proche. On va donc mettre ces séquences là dans l'objet "ps3" qui va nous servir pour la construction de l'arbre.
```{r}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```
Tip_glom est une fonction analogue à tax_glom. Il nous permet de séparer les distances cophenetiques inférieures à une valeur h. La distance cophenetique est la distance entre deux objets dans l'arbre dont les branches comprennent deux objets réduits en une branche. On va donc créer un objet ps4 qui portera cette caractéristique. 
```{r}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```
ici phyloseq va comparer les datas originales par rapport à l'arbre obtenu après agglomeration taxonomiques et enfin à l'arbre après les agglomerations phylogéniques. Grâce à la fonction gridExtra, nous pourrons ainsi générer ces 3 objets en un.
```{r}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
library (gridExtra)
gridExtra::grid.arrange
```
Sur la gauche nous retrouvons l'arbre original, au milieu l'arbre généré par agglomération taxonomique et à droit l'arbre généré par aggrégation phylogénique. On peut voir que les deux agglomérations nous permettent de clarifier les arbres. De plus, les arbres obtenus avec les deux types d'agglomération sont assez ressemblants.
```{r}
# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```
# Abundance value transformation : profondeur
on peut avoir besoin de transformer nos données pour pouvoir calculer des variances. 
On va d'abord utiliser la fonction "plot_abundance" pour definir un graphique d'abondance relative. Cela va nous permettre de comparer facilement les différentes échelles et les distributions d'abondance avant de les transformer.
Ici nous allons choisir d'observer l'abondance des bactéries du phylum "Bdellovironota" en fonction de la profondeur. Ce phylum est interessant car il est assez présent mais non majoritaire, ce qui nous permettra de voir si il va vraiment varier en fonction des prélevements, alors que les phylums très représentés seront surement assez stables. 
```{r}
plot_abundance_P = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Bdellovibrionota"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "Profondeur",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```
la fonction "transform_sample_counts" pour transformer les dénombrements en leur fréquence par rapport à leurs abondances relatives.
```{r}
# Transform to relative abundance. Save as new object.
ps3ra_P = transform_sample_counts(ps3, function(x){x / sum(x)})
```
On va donc pouvoir tracer le graphique des valeurs d'abondances avant et après transformation. On peut voir qu'après les transformations, les valeurs d'abondances relatives sont mieux réparties et permettent une lecture plus aisées des différents paramètres. Nous pouvons voir ici que c'est la famille des Bdellovibrionales qui est plus abondante par rapport aux bacteriovoracales. Nous allons donc les isoler aux codes suivant pour mieux les étudier. 

```{r}
plotBefore_P= plot_abundance_P(ps3,"")
plotAfter_P = plot_abundance_P(ps3ra_P,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 1,  plotBefore_P, plotAfter_P)
```

Ici nous avons voulu analyser l'ordre des Bdellovibrio, dont fait partie la clade OM27. 
Lorsqu'on regarde les graphiques, on remarque les abondances relatives en fonction de la profondeur comme expliqué precemment. Ici nous pouvons voir qu'en profondeur, cette clade à une abondance supérieur à par rapport aux autres, et cette abondance décline au fur et à mesure qu'on remonte à la surface. 
```{r}
psOrd_P = subset_taxa(ps3ra_P, Order == "Bdellovibrionales")
plot_abundance_P(psOrd_P, Facet = "Genus", Color = NULL)
```
# Abundance value transformation : date
on peut avoir besoin de transformer nos données pour pouvoir calculer des variances. 
On va d'abord utiliser la fonction "plot_abundance" pour definir un graphique d'abondance relative. Cela va nous permettre de comparer facilement les différentes échelles et les distributions d'abondance avant de les transformer. Ici nous nous intéressons donc à la variance en fonction de la date pour compléter les analyses faites en profondeur.
```{r}
plot_abundance_D = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Bdellovibrionota"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "Date",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```
la fonction "transform_sample_counts" pour transformer les dénombrements en leur fréquence par rapport à leurs abondances relatives.
```{r}
# Transform to relative abundance. Save as new object.
ps3ra_D = transform_sample_counts(ps3, function(x){x / sum(x)})
```
On va donc pouvoir tracer le graphique des valeurs d'abondances avant et après transformation. On peut voir qu'après les transformations, les valeurs d'abondances relatives sont mieux réparties et permettent une lecture plus aisées des différents paramètres. 

```{r}
plotBefore_D= plot_abundance_D(ps3,"")
plotAfter_D = plot_abundance_D(ps3ra_D,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 1,  plotBefore_D, plotAfter_D)
```
En regardant cette analyse, nous pouvons voirqu'il y a une différence d'abondance notable pour la clade OM27 par rapport à la date de prélevement. 
Ces bactéries sont très abondantes au sein des échantillons prélevés en septembre, tandis qu'ils sont moins présents (un facteur 10 en moins) en mars.
Nous pouvons donc voir, au vu des analyses par date et par profondeur, que les bactéries appartenant à cette clade seront plutôt retrouvées en grande quantité en profondeur en sortie d'été où l'eau est surement un peu plus chaude, par rapport à mars. Selon un article intitulé "Diverse, uncultivated bacteria and archaea underlying the cycling of dissolved protein in the ocean" par William D Orsi et al., les bactéries de la clade OM27 sont proches des bdellovibrios ce qui est logique par rapport à nos codes, et sont des bactéries très présentes dans les océans. Ce sont des bactéries qui n'ont pas encore été cultivées, et seraient probablement des bactéries prédatrices, influant sur la présence des protéines dissoutes dans l'océan. Cette caractéristique peut peut être nous aider à comprendre sa distribution : 
En hiver, la nourriture se fait peut-être plus rare, alors qu'en été l'eau est plus riche en nutriments et en proies potentielles pour OM27, ce qui permet de mieux se developper. Sa présence dans les pronfondeurs pourrait être expliquée par la température et l'oxygénation de l'eau qui serait plus adéquate pour l'organisme. Nous pouvons aussi supposer que la surface et le milieu médian contiennent également des prédateurs, qui rentreraient en compétition avec OM27, ce qui l'inciterait à plutôt se developper en profondeur.  
```{r}
psOrd_D = subset_taxa(ps3ra_D, Order == "Bdellovibrionales")
plot_abundance_D(psOrd_D, Facet = "Genus", Color = NULL)
```

# Different Ordination Projections
Nous allons demander à la machine de nous calculer une analyse par PcoA en utilisant l'indice de dissimilarité de Bray-Curtis. Ici nous allons donc pouvoir regrouper ensemble les échantillons les plus proches et les différencier des échantillons vraiment différents. 
```{r}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```
On peut donc voir que tous les échantillons de mars sont regroupés ensemble, sans distinction entre la surface et la profondeur. Cela correspond avec ce qui était attendu au vu de l'analyse de l'alpha diversité. En septembre nous pouvons voir que cette fois ci les echantillons sont séparés en fonction de la profondeur à laquelle ils ont été prélevés. Cela correspond aussi avec ce que nous avons vu lors de l'analyse de l'alpha diversité : les échantillons de surface sont regroupés ensemble, idem pour le milieu médian et profond. 
```{r}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "Date",
                  shape = "Profondeur") +
  labs(col = "Date", shape = "Pronfondeur")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
# Double principal coordinates analysis (DPCoA)
Nous vons voulu voir si cette tendance etait conservée lors d'une DPCoA. Cela nous permet de souligner les distances entre les echantillons en utilisant une table d'abondance et les données phylogénétiques. Cela permet de renforcer les différences trouvées entre les échantillons. Ici nous pouvons donc voir la même chose que pour la PCoA. Les échantillons fond/surface restent bien mélangés en mars. Cela nous montre que les communautés varient assez peu comme nous avons pu supposer. En revanche en septembre les communautés restent bien séparées en fonction des profondeurs. 
```{r}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "Date",
                  shape = "Profondeur") +
  labs(col = "Date", shape = "Profondeur")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Ici nous avons voulu faire une ordination permettant de voir la dissimilarité entre les phylums. Nous pouvons voir se distinguer 4 grands phylums qui se trouvent à part : les cyanobactéries,les bdellvibrios/Bacteroidota, les marinimicrobia et les protéobatéria. Les autres phylums sont confondus. Ces 5 phylums seront donc sûrement les phylums clef pour expliquer les répartitions de communauté, car ils sont assez dissimilaires entre eux pour être correctement distinguables. 
```{r}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") +
  coord_fixed(sqrt(evals[6] / evals[10]))
```
