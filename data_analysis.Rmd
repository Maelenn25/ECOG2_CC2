---
title: "R Notebook"
output: 
  github_document:
    toc: true
    toc_depth: 2
---

```{r}
library (phyloseq)
library(ggplot2)
library (dada2)
library(Biostrings)
library (DECIPHER)
theme_set(theme_bw())
```

```{bash}
wget https://pagesperso.univ-brest.fr/~maignien/teaching/M1-MFA/UE-Ecogenomique2/EcoG2_data_cc2.tar.gz
tar xvzf EcoG2_data_cc2.tar.gz
```

#création variable
```{r}
path <- "~/ECOG2_CC2/sequences_reunies" # CHANGE ME to the directory containing the fastq files after unzipping.
list.files(path)
```
## filtration et retirage des sequences basse qualité
```{r}
# Sort ensures forward/reverse reads are in same order
fnFs <- sort(list.files(path, pattern="_R1.fastq"))
fnRs <- sort(list.files(path, pattern="_R2.fastq"))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "R"), `[`,1)
# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)
print(fnRs)
```

```{r}
fnRs[1:11]
```

```{r}
plotQualityProfile(fnFs[1:3])
```

```{r}
plotQualityProfile(fnRs[1:2])
```

```{r}
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
sample.names
print(filtFs)
```

```{r}
out<-filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,200),trimLeft=c(21),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
```

```{r}
head(out)
```
# Learn the Error Rates
 Nous allons ici utiliser des lignes de commandes qui vont permettre d'apprendre à la machine les différents profils d'erreurs générées lors du séquençage. L'opération est faite sur les deux types de séquence.
 
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```

```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
Chaque transition (mutation) possible (A→C, A→G, ...) le taux d'erreur sont indiqués. 
-points : les taux d'erreur observés pour chaque score de qualité du consensus. 
-ligne noire : taux d'erreur estimés après convergence de l'algorithme d'apprentissage machine. 
-ligne rouge : taux d'erreur attendus selon la définition nominale du Q-score.
```{r}
plotErrors(errF, nominalQ=TRUE)
```

```{r}
plotErrors(errR, nominalQ=TRUE)
```
# Sample Inference
Ici nous créons une autre variable "dadaFs" dans laquelle nous mettons les fichiers obtenus après avoir filtré et appliqué le profil d'erreur à nos séquences. Nous allons faire la même chose avec dadaRS.

```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```

```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
Cette commande nous permet de visualiser le résultat global qu'on retrouve classé dans la liste dadaFs. Ils nous indiquent que sur les séquences on retrouve 128 séquences qui correspondent aux vrais variants, par rapport aux 1979 séquences. Ils nous indiquent aussi les diagnostiques de qualité.
```{r}
dadaFs[[1]]
```
# Merge paired reads
Ici nous voulons mettre en une seule séquence les Forwards et les Reverses.Nous pouvons faire cette opération grâce aux overlaps de 12 paires de base. Cela se fait grâce à un alignement entre les forwards et les reverses qui vont permettre de contruire les contigs.
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
# Construct sequence table
Nous allons construire une table des variations de séquence dans les amplicons (ASV) qui permet une meilleure résolution que les tables OTUs 97%
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```

```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```
# Remove chimeras
Malgré qu'on ait pu appliquer les modèles d'erreurs aux séquences, il reste des chimères. Ces chimères sont facilement reconnaissables par la machine et peuvent etre réparées en y rajoutant les parties droites et gauche des 2 séquences les plus abondantes.
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
Ici on peut voir qu'on à 22% de chimères dans notre jeu de donnée.
```{r}
1-sum(seqtab.nochim)/sum(seqtab)
```
# Track reads through the pipeline
Ce code nous permet de visualiser le nombre de séquences obtenues à la suite de toutes nos manipulations de filtrage. Ici nous pouvons voir qu'on a pu récupérer la plupart de nos séquences brutes, ce qui est signe d'une bonne qualité de séquençage.
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
# Assign taxonomy
Ici nous avons du récupérer silva afin d'analyser et d'assigner les taxonomies.
```{bash}
wget https://zenodo.org/record/3986799/files/silva_nr99_v138_train_set.fa.gz
```
Ici nous créons une variable qui va recevoir les espèces obtenues grâce à Silva

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "/home/rstudio/ECOG2_CC2/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)
```

```{r}
taxa <- addSpecies(taxa, "/home/rstudio/ECOG2_CC2/silva_species_assignment_v138.fa.gz")
```
On remarque donc après avoir affiché la table qu'on a créée on obtient une majorité de  Bacteroidetes ce qui est normal dans des échantillons fécaux. D'autres espèces n'ont pas pu être assignées car on a peu de données sur les bactéries des intestins des souris. 
```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```

# Taxonomic Filtering

```{r}
samples.out <- rownames(seqtab.nochim)
profondeur <- sapply(strsplit(samples.out, "D"), `[`, 1)
date <- substr(profondeur,0,11)
samdf <- data.frame(Profondeur=profondeur, Date=date)
samdf$Profondeur[samdf$Date>11] <- c("Fond","Median","Surface")
samdf$Date[samdf$Profondeur>11] <- c("10sept14","11mars15")
rownames(samdf) <- samples.out
```
```{r}
write.csv(samdf, "samdf.csv")
```

```{r}
samdf <-read.table("~/ECOG2_CC2/samdf.csv", sep=",", header=TRUE, row.names = 1)
```

```{r}
library(phangorn)
library(DECIPHER)
seqs <- getSequences(seqtab.nochim)
names(seqs) <- seqs # This propagates to the tip labels of the tree
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA,verbose=FALSE)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) # Note, tip order != sequence order
fit = pml(treeNJ, data=phangAlign)
fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0))
detach("package:phangorn", unload=TRUE)
```
```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa), phy_tree(fitGTR$tree))
ps
```
```{r}
plot_richness(ps, x="Date", measures=c("Shannon", "Simpson"), color="Profondeur")
```
 Ces lignes de codes nous permettent de compter le nombre d'echantillons qu'on a pour chaque phylums.
```{r}
# Show available ranks in the dataset
rank_names(taxa)
```
Sur la table affichée, nous pouvons compter 6 échantillons qui n'ont pas de phyla defini. Cela peut etre dû à une mauvaise filtration : ce serait des artefacts.
```{r}
# Create table, number of features for each phyla
table(tax_table(ps)[, "Phylum"], exclude = NULL)
```
 Ce code nous permet de nous assurer ques les séquences pour lesquelles les anotations sont ambigues vont bien être retirées.

## Filtrage de la taxonomie
### Indiquer les rangs dans l'ensemble des données

La fonction rank-names: permet de déterminer les rangs taxonomiques de ps 
```{r}
rank_names(taxa.print)
```

```{r}
ps <- subset_taxa(ps, !is.na(Phylum) & !Phylum %in% c("", "uncharacterized"))
```
Ici nous allons mesurer la prévalence, qui sera dans le cadre de cette étude le nombre d'echantillons par taxon (avec au minimum un echantillon par taxon du coup)

```{r}
# Compute prevalence of each feature, store as data.frame
prevdf = apply(X = otu_table(ps),
               MARGIN = ifelse(taxa_are_rows(ps), yes = 1, no = 2),
               FUN = function(x){sum(x > 0)})
# Add taxonomy and total read counts to this data.frame
prevdf = data.frame(Prevalence = prevdf,
                    TotalAbundance = taxa_sums(ps),
                    tax_table(ps))
```
Cette commande nous permet d'evaluer la prévalence moyenne de chaque phylum (colonne1) et la prévalence totale (colonne2). Les résultats de cette commande nous montre que Fusobacteria est trouvée seulement 2 fois. idem pour deinococcus-thermus qui n'est retrouvé que dans un seul échantillon (même si au sein de cet echantillon nous l'y retrouvons 52 fois).Nous allons donc le retirer car il risque de nous gêner.
```{r}
plyr::ddply(prevdf, "Phylum", function(df1){cbind(mean(df1$Prevalence),sum(df1$Prevalence))})
```

```{r}
# Define phyla to filter
filterPhyla = c("Fusobacteria", "Deinococcus-Thermus")
# Filter entries with unidentified Phylum.
ps1 = subset_taxa(ps, !Phylum %in% filterPhyla)
ps1
```
# Prevalence Filtering
 Ces manipulations nous permettent de voir si nous avons manqué de voir des echantillons mal definis ou en tres faible quantité qui devraient etre retirés. On va aussi pouvoir avoir un aperçu des séquences qui sont rangées dans chaque features. 
Ici; chaque point représente un taxa. Nous ne voyons pas de seuil de prévalence clairement établi ici. Nous avons donc des taxons assez stables. Néanmoins nous pouvons fixer manuelle le seuil de prévalence quelque part entre 0 et 10% (en verifiant qu'il n'y a pas d'impact non attendu sur la suite de l'étude)
```{r}
# Subset to the remaining phyla
prevdf1 = subset(prevdf, Phylum %in% get_taxa_unique(ps1, "Phylum"))
ggplot(prevdf1, aes(TotalAbundance, Prevalence / nsamples(ps),color=Phylum)) +
  # Include a guess for parameter
  geom_hline(yintercept = 0.05, alpha = 0.5, linetype = 2) +  geom_point(size = 2, alpha = 0.7) +
  scale_x_log10() +  xlab("Total Abundance") + ylab("Prevalence [Frac. Samples]") +
  facet_wrap(~Phylum) + theme(legend.position="none")
```
on va donc fixer un seuil de prévalence de 5%, c'est-à- dire que nous allons retirer toutes les valeurs de prévalence inferieures à 95%.
```{r}
# Define prevalence threshold as 5% of total samples
prevalenceThreshold = 0.05 * nsamples(ps)
prevalenceThreshold
```
C'est grâce à la fonction prune_taxa qu'on va pouvoir retirer les ASVs qui ne respectent pas le seuil de prévalence
```{r}
# Execute prevalence filter, using `prune_taxa()` function
keepTaxa = rownames(prevdf1)[(prevdf1$Prevalence >= prevalenceThreshold)]
ps2 = prune_taxa(keepTaxa, ps)
```

# Agglomerate taxa
on sait que les communautés microbiennes sont souvent composées de taxons qui partagent des caractéristiques communes. On va donc chercher à mettre ensemble les taxons qui sont très proches les uns de autres.
Pour cela, l'aggregation taxonomique est pratique. Elle est facile, et on peut comparer les taxons grâce à des arbres simples à rangs. Pour le generer on va pouvoir utiliser phyloseq. La première chose qui sera faite sera d'agglomerer ensemble les échantillons du même genre. 
```{r}
# How many genera would be present after filtering?
length(get_taxa_unique(ps2, taxonomic.rank = "Genus"))
```
tax_glom est une fonction qui permet de rassembler les espèces ayant une taxonomie proche. On va donc mettre ces séquences là dans l'objet "ps3" qui va nous servir pour la construction de l'arbre.
```{r}
ps3 = tax_glom(ps2, "Genus", NArm = TRUE)
```
Tip_glom est une fonction analogue à tax_glom. Il nous permet de séparer les distances cophenetiques inférieures à une valeur h. La distance cophenetique est la distance entre deux objets dans l'arbre dont les branches comprennent deux objets réduits en une branche. On va donc créer un objet ps4 qui portera cette caractéristique. 
```{r}
h1 = 0.4
ps4 = tip_glom(ps2, h = h1)
```
ici phyloseq va comparer les datas originales par rapport à l'arbre obtenu après agglomeration taxonomiques et enfin à l'arbre après les agglomerations phylogéniques. Grâce à la fonction gridExtra, nous pourrons ainsi générer ces 3 objets en un.
```{r}
multiPlotTitleTextSize = 15
p2tree = plot_tree(ps2, method = "treeonly",
                   ladderize = "left",
                   title = "Before Agglomeration") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p3tree = plot_tree(ps3, method = "treeonly",
                   ladderize = "left", title = "By Genus") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
p4tree = plot_tree(ps4, method = "treeonly",
                   ladderize = "left", title = "By Height") +
  theme(plot.title = element_text(size = multiPlotTitleTextSize))
library (gridExtra)
gridExtra::grid.arrange
```
Sur la gauche nous retrouvons l'arbre original, au milieu l'arbre généré par agglomération taxonomique et à droit l'arbre généré par aggrégation phylogénique. On peut voir que les deux agglomérations nous permettent de clarifier les arbres. De plus, les arbres obtenus avec les deux types d'agglomération sont assez ressemblant.
```{r}
# group plots together
grid.arrange(nrow = 1, p2tree, p3tree, p4tree)
```
# Abundance value transformation
on peut avoir besoin de transformer nos données pour pouvoir calculer des variances. 
On va d'abord utiliser la fonction "plot_abundance" pour definir un graphique d'abondance relative. Cela va nous permettre de comparer facilement les différentes échelles et les distributions d'abondance avant de les transformer.
```{r}
plot_abundance = function(physeq,title = "",
                          Facet = "Order", Color = "Phylum"){
  # Arbitrary subset, based on Phylum, for plotting
  p1f = subset_taxa(physeq, Phylum %in% c("Firmicutes"))
  mphyseq = psmelt(p1f)
  mphyseq <- subset(mphyseq, Abundance > 0)
  ggplot(data = mphyseq, mapping = aes_string(x = "sex",y = "Abundance",
                              color = Color, fill = Color)) +
    geom_violin(fill = NA) +
    geom_point(size = 1, alpha = 0.3,
               position = position_jitter(width = 0.3)) +
    facet_wrap(facets = Facet) + scale_y_log10()+
    theme(legend.position="none")
}
```
la fonction "transform_sample_counts" pour transformer les dénombrements en leur fréquence par rapport à leurs abondances relatives.
```{r}
# Transform to relative abundance. Save as new object.
ps3ra = transform_sample_counts(ps3, function(x){x / sum(x)})
```
On va donc pouvoir tracer le graphique des valeurs d'abondances avant et après transformation. On peut voir qu'après les transformations, les valeurs d'abondances relatives sont mieux réparties et permettent une lecture plus aisées des différents paramètres. 

```{r}
plotBefore = plot_abundance(ps3,"")
plotAfter = plot_abundance(ps3ra,"")
# Combine each plot into one graphic.
grid.arrange(nrow = 1,  plotBefore, plotAfter)
```

# Subset by taxonomy
On remarque que les Lactobacillales apparaissent comme une distribution taxonomique bimodale. On va donc chercher à examiner les taxons du genre Lactobacillales pour expliquer cette répartition bimodale. Pour cela nous allons préciser le taxon dont nous voulons avoir le graphique.
Lorsqu'on regarde les graphiques, on remarque les abondances relatives en fonction du sexe de l'hote sur lequelle les bactéries ont été prélevées.Ici il apparait donc clairement que la répartition bimodale de Lactobacillales provient Streptococcus (moins abondant) et de Lactobacillus qui a une abondance relative très élevée.
```{r}
psOrd = subset_taxa(ps3ra, Order == "Lactobacillales")
plot_abundance(psOrd, Facet = "Genus", Color = NULL)
```
# Preprocessing
Nous allons ensuite vouloir analyser les données en utilisant des projections multivariées. La fonction ci-dessous va s'interesser à l'âge des souris sur lesquelles ont été prélevées les bactéries. Les souris vont donc être +/- agées. Nous allons compter le nombre d'echantillons pour chaque catégorie d'âge. ces comptages vont être convertis en logarithmes, ce qui va permettre de stabiliser la variance. On peut ainsi visualiser que l'âge permet de répartir les échantillons entre 3 clusters séparés, ce qui incite à construire une autre variable qui prenne en compte cela.

```{r}
qplot(sample_data(ps)$age, geom = "histogram",binwidth=20) + xlab("age")
```
Ici nous allons comparer les données brutes avec les données logarithmiques. Au vu des résultats, on peut interpreter que les variances sont suffisamment normalisées avec "log(1+x)" pour pouvoir explorer les abondances relatives.
En réalité, pour d'autres analyses, cela ne sera pas suffisant. On recommande de plutot utiliser la fonction phyloseq_to_deseq2. 

```{r}
qplot(log10(rowSums(otu_table(ps))),binwidth=0.2) +
  xlab("Logged counts-per-sample")
```
# Première PcoA
ce code nous permets de tracer une PcoA grâce à l'indice de dissimilarité de Bray-Curtis. On remarque que quelques échantillons sont à part. Ils correspondent d'après les auteurs aux femelles 5 et 6 du jour 165 et aux mâles 3,4,5 et 6 du jour 175. Nous pouvons voir le nom de ces échantillons en rejoutant label= "SampleID" dans l'objet "out.wuf.log", juste après "distance = "wunifrac"". Par soucis de clarté dans cette figure, j'ai décidé de ne pas le laisser.  Nous allons explorer la relation entre ces échantillons précis afin de pouvoir analyser ce qui les lient ensembles.
```{r}
sample_data(ps)$age_binned <- cut(sample_data(ps)$age,
                          breaks = c(0, 100, 200, 400))
levels(sample_data(ps)$age_binned) <- list(Young100="(0,100]", Mid100to200="(100,200]", Old200="(200,400]")
sample_data(ps)$family_relationship=gsub(" ","",sample_data(ps)$family_relationship)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
out.wuf.log <- ordinate(pslog, method = "MDS", distance = "wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned") +
  labs(col = "Binned Age") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Avec ce code, nous cherchons à analyser les deux femelles préalablement citées.Elles contiennent un même ASV qui qui a une forte abondance relative (90%). C'est la première fois qu'il y a une telle abondance car le reste du temps il a une abondance inférieure à 20%. De plus, sa diversité est la plus basse parmis tous les échantillons.
```{r}
rel_abund <- t(apply(otu_table(ps), 1, function(x) x / sum(x)))
qplot(rel_abund[, 12], geom = "histogram",binwidth=0.05) +
  xlab("Relative abundance")
```
# Different Ordination Projections
On va chercher à avoir des matrices de distance et différentes méthodes d'ordination qui vont nous permettre d'analyser les données. Nous allons donc retirer les "outliers" dans un premier temps, soit les échantillons qui avaient une dissimilarité forte par rapport au reste des échantillons.
```{r}
outliers <- c("F5D165", "F6D165", "M3D175", "M4D175", "M5D175", "M6D175")
ps <- prune_samples(!(sample_names(ps) %in% outliers), ps)
```
De plus, nous retirons les échantillons qui contiennent moins de 1000 reads.
```{r}
which(!rowSums(otu_table(ps)) > 1000)
```

```{r}
ps <- prune_samples(rowSums(otu_table(ps)) > 1000, ps)
pslog <- transform_sample_counts(ps, function(x) log(1 + x))
```

# Autres PcoA
Nous allons demander à la machine de nous calculer une analyse par PcoA en utilisant l'indice de dissimilarité de Bray-Curtis. En regardant la figure obetnue, on peut clairement voir que l'age influence les communautés microbiennes retrouvées, avec une séparation vraiment nette entre les ASV des souris jeune et les souris d'âge moyen. Les souris plus agées semblent être retrouvées groupées avec les ASVs des souris moyennement agées. Si nous observons le second axe, nous pouvons trouver que les échantillons avec un plus grand score, ce qui correspond aux échantillons des souris moyennement agées et plus agées, sont les échantillons avec beaucoup de taxon appartenant aux Bacteroidetes avec un sous groupe de Firmicutes.
```{r}
out.pcoa.log <- ordinate(pslog,  method = "MDS", distance = "bray")
evals <- out.pcoa.log$values[,1]
plot_ordination(pslog, out.pcoa.log, color = "age_binned",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
# Double principal coordinates analysis (DPCoA)
Cette PcoA est clairement dominée par l'axe 1, qui exprime 75% de variabilité, contre 8,5 sur l'Axe2. Cela est obtenu dû à l'ajout des informations phylogénétiques pour pouvoir générer cette PcoA.
```{r}
out.dpcoa.log <- ordinate(pslog, method = "DPCoA")
evals <- out.dpcoa.log$eig
plot_ordination(pslog, out.dpcoa.log, color = "age_binned",
                  shape = "family_relationship") +
  labs(col = "Binned Age", shape = "Litter")+
  coord_fixed(sqrt(evals[2] / evals[1]))
```
Nous allons donc chercher quel taxa est responsable de la PcoA juste au dessus. Pour cela nous allons faire un DPcoA, qui utilise l'abondance et les informations phylogénétiques contenues dans la classe phyloseq. L'objet final représente la distance patristique (somme des longueurs des branches qui joignent deux points) et cophenetique développée plus haut. Dans cette DPcoA, nous pouvons revoir que l'âge a un effet dans cette répartition. On peut y voir que quasiment tous les phylums représentés sur cette DPcoA sont ensembles, mis à part les Bactéroidetes qui sont assez dissimilaires au reste.  
```{r}
plot_ordination(pslog, out.dpcoa.log, type = "species", color = "Phylum") +
  coord_fixed(sqrt(evals[2] / evals[1]))
```

Lorsqu'on reproduit la PCoA dominée par l'Axe 1 en utilisant unifrac comme indice de distance Unifrac, nous obtenons une PcoA beaucoup plus lisible.
Grâce à ces exemples, on peut se rendre compte qu'il est important d'adapter sa technique de projection par rapport aux datas afin de mieux les visualiser.
```{r}
out.wuf.log <- ordinate(pslog, method = "PCoA", distance ="wunifrac")
evals <- out.wuf.log$values$Eigenvalues
plot_ordination(pslog, out.wuf.log, color = "age_binned",
                  shape = "family_relationship") +
  coord_fixed(sqrt(evals[2] / evals[1])) +
  labs(col = "Binned Age", shape = "Litter")